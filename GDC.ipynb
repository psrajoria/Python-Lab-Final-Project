{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a48aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dbbc45d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"# lstm autoencoder recreate sequence\\n\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import LSTM\\nfrom keras.layers import Dense\\nfrom keras.layers import RepeatVector\\nfrom keras.layers import TimeDistributed\\nfrom keras.utils.vis_utils import plot_model\\nfrom random import randint\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\";\n",
       "                var nbb_formatted_code = \"# lstm autoencoder recreate sequence\\n\\nimport numpy as np\\nfrom keras.models import Sequential\\nfrom keras.layers import LSTM\\nfrom keras.layers import Dense\\nfrom keras.layers import RepeatVector\\nfrom keras.layers import TimeDistributed\\nfrom keras.utils.vis_utils import plot_model\\nfrom random import randint\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lstm autoencoder recreate sequence\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b43162d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"##  Generate Data\\n\\n\\nimport numpy as np\\nimport random\\n\\nrandom.seed(42)\\n\\n\\ndef random_dna_sequence(length):\\n    return \\\"\\\".join(random.choice(\\\"ACTG\\\") for _ in range(length))\\n\\n\\ndef base_frequency(dna):\\n    d = {}\\n    for base in \\\"ATCG\\\":\\n        d[base] = dna.count(base) / float(len(dna))\\n    return d\\n\\n\\ndata = []\\nfor _ in range(10):\\n    dna = random_dna_sequence(25)\\n    data.append(dna)\\n#     print(dna, base_frequency(dna))\";\n",
       "                var nbb_formatted_code = \"##  Generate Data\\n\\n\\nimport numpy as np\\nimport random\\n\\nrandom.seed(42)\\n\\n\\ndef random_dna_sequence(length):\\n    return \\\"\\\".join(random.choice(\\\"ACTG\\\") for _ in range(length))\\n\\n\\ndef base_frequency(dna):\\n    d = {}\\n    for base in \\\"ATCG\\\":\\n        d[base] = dna.count(base) / float(len(dna))\\n    return d\\n\\n\\ndata = []\\nfor _ in range(10):\\n    dna = random_dna_sequence(25)\\n    data.append(dna)\\n#     print(dna, base_frequency(dna))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Generate Data\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def random_dna_sequence(length):\n",
    "    return \"\".join(random.choice(\"ACTG\") for _ in range(length))\n",
    "\n",
    "\n",
    "def base_frequency(dna):\n",
    "    d = {}\n",
    "    for base in \"ATCG\":\n",
    "        d[base] = dna.count(base) / float(len(dna))\n",
    "    return d\n",
    "\n",
    "\n",
    "data = []\n",
    "for _ in range(10):\n",
    "    dna = random_dna_sequence(25)\n",
    "    data.append(dna)\n",
    "#     print(dna, base_frequency(dna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f56fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"letters = [list(x) for x in data]\";\n",
       "                var nbb_formatted_code = \"letters = [list(x) for x in data]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letters = [list(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56afbab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 86;\n",
       "                var nbb_unformatted_code = \"type(letters)\";\n",
       "                var nbb_formatted_code = \"type(letters)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f31a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"arr = np.array(letters)\";\n",
       "                var nbb_formatted_code = \"arr = np.array(letters)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = np.array(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba66bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 25)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"arr.shape\";\n",
       "                var nbb_formatted_code = \"arr.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "39907bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"def one_hot(array):\\n    unique, inverse = np.unique(array, return_inverse=True)\\n    onehot = np.eye(unique.shape[0])[inverse]\\n    return onehot\\n\\n\\nap = one_hot(arr)\";\n",
       "                var nbb_formatted_code = \"def one_hot(array):\\n    unique, inverse = np.unique(array, return_inverse=True)\\n    onehot = np.eye(unique.shape[0])[inverse]\\n    return onehot\\n\\n\\nap = one_hot(arr)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot(array):\n",
    "    unique, inverse = np.unique(array, return_inverse=True)\n",
    "    onehot = np.eye(unique.shape[0])[inverse]\n",
    "    return onehot\n",
    "\n",
    "\n",
    "ap = one_hot(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd06f551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 90;\n",
       "                var nbb_unformatted_code = \"ap\";\n",
       "                var nbb_formatted_code = \"ap\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c906a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 100;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import OneHotEncoder\\n\\nohe = OneHotEncoder(categories=\\\"auto\\\", sparse=False)\\nbr = ohe.fit_transform(arr)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import OneHotEncoder\\n\\nohe = OneHotEncoder(categories=\\\"auto\\\", sparse=False)\\nbr = ohe.fit_transform(arr)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories=\"auto\", sparse=False)\n",
    "br = ohe.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c735008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 101;\n",
       "                var nbb_unformatted_code = \"br\";\n",
       "                var nbb_formatted_code = \"br\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7c932216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:  (100000, 6, 51) (100000, 3, 51) (100000, 3, 51)\n",
      "Here is first categorically encoded input sequence looks like: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"def dataset_preparation(n_in, n_out, n_unique, n_samples):\\n    X1, X2, y = [], [], []\\n    for _ in range(n_samples):\\n        ## create random numbers sequence - input \\n        inp_seq = [randint(1, n_unique-1) for _ in range(n_in)]\\n        \\n        ## create target sequence\\n        target = inp_seq[:n_out]\\n    \\n        ## create padded sequence / seed sequence \\n        target_seq = list(reversed(target))\\n        seed_seq = [0] + target_seq[:-1]  \\n        \\n        # convert the elements to categorical using keras api\\n        X1.append(to_categorical([inp_seq], num_classes=n_unique))\\n        X2.append(to_categorical([seed_seq], num_classes=n_unique))\\n        y.append(to_categorical([target_seq], num_classes=n_unique))\\n    \\n    # remove unnecessary dimention\\n    X1 = np.squeeze(np.array(X1), axis=1) \\n    X2 = np.squeeze(np.array(X2), axis=1) \\n    y  = np.squeeze(np.array(y), axis=1) \\n    return X1, X2, y\\n\\nsamples = 100000\\nfeatures = 51\\ninp_size = 6\\nout_size = 3\\n\\ninputs, seeds, outputs = dataset_preparation(inp_size, out_size, features, samples)\\nprint(\\\"Shapes: \\\", inputs.shape, seeds.shape, outputs.shape)\\nprint (\\\"Here is first categorically encoded input sequence looks like: \\\", )\\ninputs[0][0]\";\n",
       "                var nbb_formatted_code = \"def dataset_preparation(n_in, n_out, n_unique, n_samples):\\n    X1, X2, y = [], [], []\\n    for _ in range(n_samples):\\n        ## create random numbers sequence - input\\n        inp_seq = [randint(1, n_unique - 1) for _ in range(n_in)]\\n\\n        ## create target sequence\\n        target = inp_seq[:n_out]\\n\\n        ## create padded sequence / seed sequence\\n        target_seq = list(reversed(target))\\n        seed_seq = [0] + target_seq[:-1]\\n\\n        # convert the elements to categorical using keras api\\n        X1.append(to_categorical([inp_seq], num_classes=n_unique))\\n        X2.append(to_categorical([seed_seq], num_classes=n_unique))\\n        y.append(to_categorical([target_seq], num_classes=n_unique))\\n\\n    # remove unnecessary dimention\\n    X1 = np.squeeze(np.array(X1), axis=1)\\n    X2 = np.squeeze(np.array(X2), axis=1)\\n    y = np.squeeze(np.array(y), axis=1)\\n    return X1, X2, y\\n\\n\\nsamples = 100000\\nfeatures = 51\\ninp_size = 6\\nout_size = 3\\n\\ninputs, seeds, outputs = dataset_preparation(inp_size, out_size, features, samples)\\nprint(\\\"Shapes: \\\", inputs.shape, seeds.shape, outputs.shape)\\nprint(\\n    \\\"Here is first categorically encoded input sequence looks like: \\\",\\n)\\ninputs[0][0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataset_preparation(n_in, n_out, n_unique, n_samples):\n",
    "    X1, X2, y = [], [], []\n",
    "    for _ in range(n_samples):\n",
    "        ## create random numbers sequence - input\n",
    "        inp_seq = [randint(1, n_unique - 1) for _ in range(n_in)]\n",
    "\n",
    "        ## create target sequence\n",
    "        target = inp_seq[:n_out]\n",
    "\n",
    "        ## create padded sequence / seed sequence\n",
    "        target_seq = list(reversed(target))\n",
    "        seed_seq = [0] + target_seq[:-1]\n",
    "\n",
    "        # convert the elements to categorical using keras api\n",
    "        X1.append(to_categorical([inp_seq], num_classes=n_unique))\n",
    "        X2.append(to_categorical([seed_seq], num_classes=n_unique))\n",
    "        y.append(to_categorical([target_seq], num_classes=n_unique))\n",
    "\n",
    "    # remove unnecessary dimention\n",
    "    X1 = np.squeeze(np.array(X1), axis=1)\n",
    "    X2 = np.squeeze(np.array(X2), axis=1)\n",
    "    y = np.squeeze(np.array(y), axis=1)\n",
    "    return X1, X2, y\n",
    "\n",
    "\n",
    "samples = 100000\n",
    "features = 51\n",
    "inp_size = 6\n",
    "out_size = 3\n",
    "\n",
    "inputs, seeds, outputs = dataset_preparation(inp_size, out_size, features, samples)\n",
    "print(\"Shapes: \", inputs.shape, seeds.shape, outputs.shape)\n",
    "print(\n",
    "    \"Here is first categorically encoded input sequence looks like: \",\n",
    ")\n",
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb112b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1, 6, 51) (100000, 1, 3, 51) (100000, 1, 3, 51)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, None, 51), found shape=(32, 1, 6, 51)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16464/3922256641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;31m# evaluate LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\users\\psraj\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, None, 51), found shape=(32, 1, 6, 51)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 110;\n",
       "                var nbb_unformatted_code = \"from random import randint\\nfrom numpy import array\\nfrom numpy import argmax\\nfrom numpy import array_equal\\nfrom tensorflow.keras.utils import to_categorical\\nfrom keras.models import Model\\nfrom keras.layers import Input\\nfrom keras.layers import LSTM\\nfrom keras.layers import Dense\\n\\n# generate a sequence of random integers\\ndef generate_sequence(length, n_unique):\\n    return [randint(1, n_unique - 1) for _ in range(length)]\\n\\n\\n# prepare data for the LSTM\\ndef get_dataset(n_in, n_out, cardinality, n_samples):\\n    X1, X2, y = list(), list(), list()\\n    for _ in range(n_samples):\\n        # generate source sequence\\n        source = generate_sequence(n_in, cardinality)\\n        # define padded target sequence\\n        target = source[:n_out]\\n        target.reverse()\\n        # create padded input target sequence\\n        target_in = [0] + target[:-1]\\n        # encode\\n        src_encoded = to_categorical([source], num_classes=cardinality)\\n        tar_encoded = to_categorical([target], num_classes=cardinality)\\n        tar2_encoded = to_categorical([target_in], num_classes=cardinality)\\n        # store\\n        X1.append(src_encoded)\\n        X2.append(tar2_encoded)\\n        y.append(tar_encoded)\\n    return array(X1), array(X2), array(y)\\n\\n\\n# returns train, inference_encoder and inference_decoder models\\ndef define_models(n_input, n_output, n_units):\\n    # define training encoder\\n    encoder_inputs = Input(shape=(None, n_input))\\n    encoder = LSTM(n_units, return_state=True)\\n    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\\n    encoder_states = [state_h, state_c]\\n    # define training decoder\\n    decoder_inputs = Input(shape=(None, n_output))\\n    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\\n    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\\n    decoder_dense = Dense(n_output, activation=\\\"softmax\\\")\\n    decoder_outputs = decoder_dense(decoder_outputs)\\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\\n    # define inference encoder\\n    encoder_model = Model(encoder_inputs, encoder_states)\\n    # define inference decoder\\n    decoder_state_input_h = Input(shape=(n_units,))\\n    decoder_state_input_c = Input(shape=(n_units,))\\n    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\\n    decoder_outputs, state_h, state_c = decoder_lstm(\\n        decoder_inputs, initial_state=decoder_states_inputs\\n    )\\n    decoder_states = [state_h, state_c]\\n    decoder_outputs = decoder_dense(decoder_outputs)\\n    decoder_model = Model(\\n        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\\n    )\\n    # return all models\\n    return model, encoder_model, decoder_model\\n\\n\\n# generate target given source sequence\\ndef predict_sequence(infenc, infdec, source, n_steps, cardinality):\\n    # encode\\n    state = infenc.predict(source)\\n    # start of sequence input\\n    target_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\\n    # collect predictions\\n    output = list()\\n    for t in range(n_steps):\\n        # predict next char\\n        yhat, h, c = infdec.predict([target_seq] + state)\\n        # store prediction\\n        output.append(yhat[0, 0, :])\\n        # update state\\n        state = [h, c]\\n        # update target sequence\\n        target_seq = yhat\\n    return array(output)\\n\\n\\n# decode a one hot encoded string\\ndef one_hot_decode(encoded_seq):\\n    return [argmax(vector) for vector in encoded_seq]\\n\\n\\n# configure problem\\nn_features = 50 + 1\\nn_steps_in = 6\\nn_steps_out = 3\\n# define model\\ntrain, infenc, infdec = define_models(n_features, n_features, 128)\\ntrain.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\n# generate training dataset\\nX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\\nprint(X1.shape, X2.shape, y.shape)\\n# train model\\ntrain.fit([X1, X2], y, epochs=1)\\n# evaluate LSTM\\ntotal, correct = 100, 0\\nfor _ in range(total):\\n    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\\n    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\\n    if array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\\n        correct += 1\\nprint(\\\"Accuracy: %.2f%%\\\" % (float(correct) / float(total) * 100.0))\\n# spot check some examples\\nfor _ in range(10):\\n    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\\n    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\\n    print(\\n        \\\"X=%s y=%s, yhat=%s\\\"\\n        % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target))\\n    )\";\n",
       "                var nbb_formatted_code = \"from random import randint\\nfrom numpy import array\\nfrom numpy import argmax\\nfrom numpy import array_equal\\nfrom tensorflow.keras.utils import to_categorical\\nfrom keras.models import Model\\nfrom keras.layers import Input\\nfrom keras.layers import LSTM\\nfrom keras.layers import Dense\\n\\n# generate a sequence of random integers\\ndef generate_sequence(length, n_unique):\\n    return [randint(1, n_unique - 1) for _ in range(length)]\\n\\n\\n# prepare data for the LSTM\\ndef get_dataset(n_in, n_out, cardinality, n_samples):\\n    X1, X2, y = list(), list(), list()\\n    for _ in range(n_samples):\\n        # generate source sequence\\n        source = generate_sequence(n_in, cardinality)\\n        # define padded target sequence\\n        target = source[:n_out]\\n        target.reverse()\\n        # create padded input target sequence\\n        target_in = [0] + target[:-1]\\n        # encode\\n        src_encoded = to_categorical([source], num_classes=cardinality)\\n        tar_encoded = to_categorical([target], num_classes=cardinality)\\n        tar2_encoded = to_categorical([target_in], num_classes=cardinality)\\n        # store\\n        X1.append(src_encoded)\\n        X2.append(tar2_encoded)\\n        y.append(tar_encoded)\\n    return array(X1), array(X2), array(y)\\n\\n\\n# returns train, inference_encoder and inference_decoder models\\ndef define_models(n_input, n_output, n_units):\\n    # define training encoder\\n    encoder_inputs = Input(shape=(None, n_input))\\n    encoder = LSTM(n_units, return_state=True)\\n    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\\n    encoder_states = [state_h, state_c]\\n    # define training decoder\\n    decoder_inputs = Input(shape=(None, n_output))\\n    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\\n    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\\n    decoder_dense = Dense(n_output, activation=\\\"softmax\\\")\\n    decoder_outputs = decoder_dense(decoder_outputs)\\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\\n    # define inference encoder\\n    encoder_model = Model(encoder_inputs, encoder_states)\\n    # define inference decoder\\n    decoder_state_input_h = Input(shape=(n_units,))\\n    decoder_state_input_c = Input(shape=(n_units,))\\n    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\\n    decoder_outputs, state_h, state_c = decoder_lstm(\\n        decoder_inputs, initial_state=decoder_states_inputs\\n    )\\n    decoder_states = [state_h, state_c]\\n    decoder_outputs = decoder_dense(decoder_outputs)\\n    decoder_model = Model(\\n        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\\n    )\\n    # return all models\\n    return model, encoder_model, decoder_model\\n\\n\\n# generate target given source sequence\\ndef predict_sequence(infenc, infdec, source, n_steps, cardinality):\\n    # encode\\n    state = infenc.predict(source)\\n    # start of sequence input\\n    target_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\\n    # collect predictions\\n    output = list()\\n    for t in range(n_steps):\\n        # predict next char\\n        yhat, h, c = infdec.predict([target_seq] + state)\\n        # store prediction\\n        output.append(yhat[0, 0, :])\\n        # update state\\n        state = [h, c]\\n        # update target sequence\\n        target_seq = yhat\\n    return array(output)\\n\\n\\n# decode a one hot encoded string\\ndef one_hot_decode(encoded_seq):\\n    return [argmax(vector) for vector in encoded_seq]\\n\\n\\n# configure problem\\nn_features = 50 + 1\\nn_steps_in = 6\\nn_steps_out = 3\\n# define model\\ntrain, infenc, infdec = define_models(n_features, n_features, 128)\\ntrain.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_crossentropy\\\", metrics=[\\\"accuracy\\\"])\\n# generate training dataset\\nX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\\nprint(X1.shape, X2.shape, y.shape)\\n# train model\\ntrain.fit([X1, X2], y, epochs=1)\\n# evaluate LSTM\\ntotal, correct = 100, 0\\nfor _ in range(total):\\n    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\\n    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\\n    if array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\\n        correct += 1\\nprint(\\\"Accuracy: %.2f%%\\\" % (float(correct) / float(total) * 100.0))\\n# spot check some examples\\nfor _ in range(10):\\n    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\\n    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\\n    print(\\n        \\\"X=%s y=%s, yhat=%s\\\"\\n        % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target))\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# generate a sequence of random integers\n",
    "def generate_sequence(length, n_unique):\n",
    "    return [randint(1, n_unique - 1) for _ in range(length)]\n",
    "\n",
    "\n",
    "# prepare data for the LSTM\n",
    "def get_dataset(n_in, n_out, cardinality, n_samples):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for _ in range(n_samples):\n",
    "        # generate source sequence\n",
    "        source = generate_sequence(n_in, cardinality)\n",
    "        # define padded target sequence\n",
    "        target = source[:n_out]\n",
    "        target.reverse()\n",
    "        # create padded input target sequence\n",
    "        target_in = [0] + target[:-1]\n",
    "        # encode\n",
    "        src_encoded = to_categorical([source], num_classes=cardinality)\n",
    "        tar_encoded = to_categorical([target], num_classes=cardinality)\n",
    "        tar2_encoded = to_categorical([target_in], num_classes=cardinality)\n",
    "        # store\n",
    "        X1.append(src_encoded)\n",
    "        X2.append(tar2_encoded)\n",
    "        y.append(tar_encoded)\n",
    "    return array(X1), array(X2), array(y)\n",
    "\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(n_input, n_output, n_units):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs\n",
    "    )\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    "    )\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "# generate target given source sequence\n",
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0, 0, :])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return array(output)\n",
    "\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "\n",
    "# configure problem\n",
    "n_features = 50 + 1\n",
    "n_steps_in = 6\n",
    "n_steps_out = 3\n",
    "# define model\n",
    "train, infenc, infdec = define_models(n_features, n_features, 128)\n",
    "train.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# generate training dataset\n",
    "X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\n",
    "print(X1.shape, X2.shape, y.shape)\n",
    "# train model\n",
    "train.fit([X1, X2], y, epochs=1)\n",
    "# evaluate LSTM\n",
    "total, correct = 100, 0\n",
    "for _ in range(total):\n",
    "    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "    if array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\n",
    "        correct += 1\n",
    "print(\"Accuracy: %.2f%%\" % (float(correct) / float(total) * 100.0))\n",
    "# spot check some examples\n",
    "for _ in range(10):\n",
    "    X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "    target = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "    print(\n",
    "        \"X=%s y=%s, yhat=%s\"\n",
    "        % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a16c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
